{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Module 6: Secondary Aims Using Data Arising from a SMART -- R Code Tutorial\n\n**Authors:** Nicholas J. Seewald, Daniel Almirall, Inbal Nahum-Shani, Audrey Boruvka, and Susan A. Murphy\n\n**Date:** March 20, 2020\n\nThis file provides example R code to analyze *simulated* data that was generated to mimic data arising from the ADHD SMART study (PI: William Pelham). An accompanying handout (\"ADHD Handout.pdf\") describes the variables in the data.\n\nTranslation of SAS code from Modules 3 and 4 into R is by Audrey Boruvka and Nicholas J. Seewald [(email)](mailto:nseewald@umich.edu). Notebooks created by [Nicholas J. Seewald](https://nickseewald.com).\n\n### Contents:\n- [Part (a): Compare means from two embedded adaptive interventions](#part-a)\n- [Part (b): Compare all four embedded AIs with one regression](#part-b)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Setup\nAs in [Module 3](module3tutorial.ipynb) and [Module 4](module4tutorial.ipynb), we will begin by loading the data. We omit summaries here for brevity; see [module3tutorial.ipynb](module3tutorial.ipynb) for details on the data we will be using in this tutorial. The block of code below performs all necessary pre-processing steps from Module 3 related to loading and sorting the data, as well as centering covariates. **See Module 3 for details on this code; otherwise just run the cells and move to Part (a).**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "library(geepack)\nsource('functions.R')",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "function 'estimate' loaded successfully.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "adhd <- read.csv(\"adhd-simulated-dataset.csv\")\n\n# R is case-sensitive! Avoid issues by changing variable names to all lowercase\nnames(adhd) <- tolower(names(adhd))\n\n# Handle missing data: set \"NaN\" values to \"NA\" (R's missing data value)\nadhd$o21[is.nan(adhd$o21)] <- NA\nadhd$a2[is.nan(adhd$a2)] <- NA\n\n# Sort data by ID\nadhd <- adhd[order(adhd$id), ]\n\nadhd$o11c <- with(adhd, o11 - mean(o11))\nadhd$o12c <- with(adhd, o12 - mean(o12))\nadhd$o13c <- with(adhd, o13 - mean(o13))\nadhd$o14c <- with(adhd, o14 - mean(o14))\n## o21 is measured among non-responders only\nadhd$o22c <- with(adhd, o22 - mean(o22))\n\n## center baseline variables using mean among non-responders\nadhd$o11cnr <- adhd$o12cnr <- adhd$o13cnr <- adhd$o14cnr <- NA\nadhd$o21cnr <- adhd$o22cnr <- NA\nadhd$o11cnr[adhd$r == 0] <- with(subset(adhd, r == 0), o11 - mean(o11))\nadhd$o12cnr[adhd$r == 0] <- with(subset(adhd, r == 0), o12 - mean(o12))\nadhd$o13cnr[adhd$r == 0] <- with(subset(adhd, r == 0), o13 - mean(o13))\nadhd$o14cnr[adhd$r == 0] <- with(subset(adhd, r == 0), o14 - mean(o14))\nadhd$o21cnr[adhd$r == 0] <- with(subset(adhd, r == 0), o21 - mean(o21))\nadhd$o22cnr[adhd$r == 0] <- with(subset(adhd, r == 0), o22 - mean(o22))",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## <a name=\"part-a\"></a> Part (a): Examine moderators of second-stage treatment effect\n\nRemember that Step 1 of Q-learning is to understand how intermediate outcomes can be used to make second-stage decisions about intensifying vs. augmenting. Investigating potential moderators in this way will help us tailor the second-stage intervention for non-responders based on the status of the participants up to the point of non-response. We are only able to investigate non-responders since those were the only individuals who were re-randomized. Because all responders in this study continued on their first-stage intervention, we are unable to assess whether a different tactic would be better for some responders.\n\nWe'll start by fitting a **moderated regression model** using the data from non-responders. The goal is to discover if we can use *the initial treatment* `a1` and *adherence to initial treatment* `o22` to select a tactic for non-responders, adjusting for baseline covariates. The model is as follows:\n\n$$ E[Y \\mid \\mathbf{O_{1}}, A_1, O_{22}, A_2, R = 0] = \\beta_0 + \\beta_1 O_{11c} + \\beta_2 O_{12c} + \\beta_3 O_{13c} + \\beta_4 O_{14c} + \\beta_5 O_{21c} + \\beta_6 A_{1} + \\beta_7 O_{22} + \\beta_8 A_2 + \\beta_9 (A_2 \\times A_1) + \\beta_{10} (A_2 \\times O_{22})$$\n\nPay particular attention to $\\beta_6$, $\\beta_7$, $\\beta_9$, and $\\beta_{10}$, as these represent the main effects and interactions (with second-stage intervention), respectively, of the two moderators we are interested in for this analysis. Let's fit the model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# The argument \"x = TRUE\" requests that geeglm() return the matrix of data used to fit the model.\nfit <- geeglm(y ~ o11c + o12c + o13c + o14c + o21cnr + a1 + o22 + a2\n         + a1:a2 + a2:o22,\n         id = id, data = adhd, subset = r == 0, x = TRUE)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's look at the parameter estimates and standard errors for this model to investigate moderation of the second-stage intervention effect by first-stage intervention and adherence.\n\nUnlike `PROC GENMOD` in SAS when we have no weights, when we summarize the results from `geeglm()` it will return the \"robust\" standard errors (which we don't want here, since this is an unweighted regression). So, we'll use the `estimate()` function from [`functions.R`](https://notebooks.azure.com/nseewald/projects/getting-smart-workshop/html/functions.R) with an identity matrix for the `combos` argument. The identity matrix has 1's on the diagonal and 0's elsewhere."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mat <- diag(ncol(fit$x)) #mat is the appropriately-sized identity matrix \nrownames(mat) <- names(coef(fit)) #name the rows of mat with variable names for legibility\nestimate(fit, combos = mat)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "            Estimate 95% LCL 95% UCL     SE p-value\n(Intercept)   3.0039  2.7592  3.2486 0.1248  <1e-04\no11c         -0.2462 -0.6302  0.1378 0.1959  0.2090\no12c         -0.2961 -0.4823 -0.1100 0.0950  0.0018\no13c          0.0391 -0.3628  0.4411 0.2051  0.8486\no14c          0.4868  0.0353  0.9383 0.2304  0.0346\no21cnr       -0.0097 -0.0992  0.0797 0.0456  0.8312\na1            0.0758 -0.1019  0.2535 0.0907  0.4030\no22          -0.0980 -0.4548  0.2588 0.1820  0.5903\na2           -0.8640 -1.1150 -0.6130 0.1280  <1e-04\na1:a2        -0.1934 -0.3754 -0.0115 0.0928  0.0372\no22:a2        1.1826  0.8194  1.5458 0.1853  <1e-04"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see that there does appear to be statisically-significant moderation of the effect of the second-stage intervention by first-stage intervention (`a1`) and adherence (`o22`). \n\nNow, we proceed to estimate contrasts of interest. In particular, we're interested in estimating the mean outcome for non-responders to either first-stage intervention at both levels of adherence and first-stage intervention."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "estimate(fit,\n  rbind(\"NR adh to med, intensify\"          = c(1, rep(0,5), -1, 1,  1, -1,  1),\n        \"NR adh to med, augment\"            = c(1, rep(0,5), -1, 1, -1,  1, -1),\n        \"Intens vs aug, NR adh to med\"      = c(0, rep(0,5),  0, 0,  2, -2,  2),\n        \"NR non-adh to med, intensify\"      = c(1, rep(0,5), -1, 0,  1, -1,  0),\n        \"NR non-adh to med, augment\"        = c(1, rep(0,5), -1, 0, -1,  1,  0),\n        \"Intens vs aug, NR non-adh to med\"  = c(0, rep(0,5),  0, 0,  2, -2,  0),\n        \"NR adh to bmod, intensify\"         = c(1, rep(0,5),  1, 1,  1,  1,  1),\n        \"NR adh to bmod, augment\"           = c(1, rep(0,5),  1, 1, -1, -1, -1),\n        \"Intens vs aug, NR adh to bmod\"     = c(0, rep(0,5),  0, 0,  2,  2,  2),\n        \"NR non-adh to bmod, intensify\"     = c(1, rep(0,5),  1, 0,  1,  1,  0),\n        \"NR non-adh to bmod, augment\"       = c(1, rep(0,5),  1, 0, -1, -1,  0),\n        \"Intens vs aug, NR non-adh to bmod\" = c(0, rep(0,5),  0, 0,  2,  2,  0)))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                  Estimate 95% LCL 95% UCL     SE p-value\nNR adh to med, intensify            3.3420  2.8960  3.7880 0.2276  <1e-04\nNR adh to med, augment              2.3180  1.9069  2.7292 0.2098  <1e-04\nIntens vs aug, NR adh to med        1.0240  0.4131  1.6350 0.3117  0.0010\nNR non-adh to med, intensify        2.2575  1.8250  2.6900 0.2207  <1e-04\nNR non-adh to med, augment          3.5986  3.1198  4.0774 0.2443  <1e-04\nIntens vs aug, NR non-adh to med   -1.3412 -1.9896 -0.6927 0.3308  0.0001\nNR adh to bmod, intensify           3.1068  2.6373  3.5763 0.2396  <1e-04\nNR adh to bmod, augment             2.8565  2.4203  3.2927 0.2226  <1e-04\nIntens vs aug, NR adh to bmod       0.2503 -0.3950  0.8956 0.3292  0.4471\nNR non-adh to bmod, intensify       2.0222  1.6235  2.4210 0.2034  <1e-04\nNR non-adh to bmod, augment         4.1371  3.7190  4.5553 0.2134  <1e-04\nIntens vs aug, NR non-adh to bmod  -2.1149 -2.7050 -1.5248 0.3011  <1e-04"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "We can plot the contrasts below, as in the slides:\n\n![\"Plot of estimated outcomes for non-responders under both second-stage interventions, by adherence and first-stage intervention\"](assets/qlearning-step1-plot.png \"Plot of estimated outcomes for non-responders under both second-stage interventions, by adherence and first-stage intervention\")"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## <a name=\"part-b\"></a> Part (b): Q-Learning using `qlaci`"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The easiest way to perform Q-learning in R is to use a package called `qlaci`. The following line of code will install the package from [d3Lab's GitHub repository](https://github.com/d3lab-isr/qlaci), via an online service called \"install-github.me\". The way it works is demonstrated below: you use `source()` to read in an R script located at a URL of the form `https://install-github.me/<username>/<repository>`. Here, the code repository we're interested in is `d3lab-isr/qlaci`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "source(\"https://install-github.me/d3lab-isr/qlaci\")\nlibrary(qlaci)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading GitHub repo d3lab-isr/qlaci@master\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\u001b[32m✔\u001b[39m  \u001b[90mchecking for file ‘/tmp/RtmpPEk8s8/remotes9c7e4e4d9a/d3lab-isr-qlaci-a0ebb23/DESCRIPTION’\u001b[39m\u001b[36m\u001b[36m (15s)\u001b[36m\u001b[39m\n\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mpreparing ‘qlaci’:\u001b[39m\u001b[36m\u001b[36m (521ms)\u001b[36m\u001b[39m\n\u001b[32m✔\u001b[39m  \u001b[90mchecking DESCRIPTION meta-information\u001b[39m\u001b[36m\u001b[36m (731ms)\u001b[36m\u001b[39m\n\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mchecking for LF line-endings in source and make files and shell scripts\u001b[39m\u001b[36m\u001b[36m (1.8s)\u001b[36m\u001b[39m\n\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mchecking for empty or unneeded directories\u001b[39m\u001b[36m\u001b[39m\n\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mlooking to see if a ‘data/datalist’ file should be added\u001b[39m\u001b[36m\u001b[39m\n\u001b[90m─\u001b[39m\u001b[90m  \u001b[39m\u001b[90mbuilding ‘qlaci_1.0.tar.gz’\u001b[39m\u001b[36m\u001b[39m\n   \n\r",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Installing package into ‘/home/nbuser/R’\n(as ‘lib’ is unspecified)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To get started with `qlaci()`, we'll need to create a `data.frame` that contains only non-responders, as these are the only individuals we can use Q-learning on. We'll call the datasest `adhdq`. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "adhdq <- adhd\nadhdq[is.na(adhdq)] <- 0",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We also need to create a contrast matrix, as we've done for the `estimate()` steps in all prior modules. This is the contrast matrix that will be used for the *stage-1 regression* (step 3 of Q-learning). `qlaci()` uses this matrix to estimate the mean outcomes under each of the first-stage treatments (averaging over the future optimal response) at both levels of \"prior med\", the baseline covariate we'd like to investigate as part of a more deeply-tailored AI."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## contrast matrix - we must transpose this for qlaci\nc1 <-\n  rbind(\"Mean Y under bmod, prior med\"          = c(1, rep(0, 3), 1,  1,  1),\n        \"Mean Y under med, prior med\"           = c(1, rep(0, 3), 1, -1, -1),\n        \"Mean diff (bmod-med) for prior med\"    = c(0, rep(0, 3), 0,  2,  2),\n        \"Mean Y under bmod, no prior med\"       = c(1, rep(0, 3), 0,  0,  1),\n        \"Mean Y under med, no prior med\"        = c(1, rep(0, 3), 0,  0, -1),\n        \"Mean diff (bmod-med) for no prior med\" = c(0, rep(0, 3), 0,  0,  2))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we're ready to jump into `qlaci()`. The first thing we need to do is \"set the random seed\". Random number generation in software is actually \"pseudo-random\" and dependent on a \"seed\". If you know the seed, you can determine the entire sequence of numbers that will be generated by the software. We'll set the seed at 0 so that we can reproduce the results of `qlaci()`. We need to do this since the confidence intervals from `qlaci()` are based on the bootstrap, which involves randomness."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## setting the random seed ensures that the results are reproducible\nset.seed(0)\n\n## with attach we can be lazy and refer to variables directly; use with caution\nattach(adhdq)\nql <- qlaci(H10 = cbind(\"intercept\" = 1, o11c, o12c, o14c, o13), \n            H11 = cbind(\"o13:a1\" = o13, \"a1\" = 1),\n            A1 = a1, \n            Y1 = rep(0, nrow(adhdq)),\n            H20 = cbind(\"intercept\" = 1, o11cnr, o12cnr, o13cnr, o14cnr, o21cnr, a1, o22),\n            H21 = cbind(\"o22:a2\" = o22, \"a1:a2\" = a1, \"a2\" = 1),\n            A2 = a2, \n            Y2 = y, \n            S = rerand,\n            c1 = t(c1))\ndetach(adhdq)\nql",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "$stg1coeff\n  intercept        o11c        o12c        o14c         o13      o13:a1 \n 3.45750188 -0.44070418 -0.33661676  0.56499489 -0.04177137 -0.56097987 \n         a1 \n 0.31039237 \n\n$stg2coeff\n   intercept       o11cnr       o12cnr       o13cnr       o14cnr       o21cnr \n 3.018295202 -0.246161848 -0.296121115  0.039141030  0.486759238 -0.009732028 \n          a1          o22       o22:a2        a1:a2           a2 \n 0.075814974 -0.098016173  1.182592125 -0.193433989 -0.864013129 \n\n$ci1\n                                             est        low        upp\nMean Y under bmod, prior med           3.1651430  2.5857085 3.62960958\nMean Y under med, prior med            3.6663180  3.3140985 4.02752148\nMean diff (bmod-med) for prior med    -0.5011750 -1.0562817 0.06274104\nMean Y under bmod, no prior med        3.7678942  3.4540746 4.05290692\nMean Y under med, no prior med         3.1471095  2.8142328 3.45923312\nMean diff (bmod-med) for no prior med  0.6207847  0.2064203 1.04375882\n\n$ci2\nNULL\n",
            "text/latex": "\\begin{description}\n\\item[\\$stg1coeff] \\begin{description*}\n\\item[intercept] 3.45750188130161\n\\item[o11c] -0.440704176030666\n\\item[o12c] -0.336616758801142\n\\item[o14c] 0.564994887809273\n\\item[o13] -0.0417713658676757\n\\item[o13:a1] -0.560979870289834\n\\item[a1] 0.310392366596432\n\\end{description*}\n\n\\item[\\$stg2coeff] \\begin{description*}\n\\item[intercept] 3.01829520209932\n\\item[o11cnr] -0.246161848150136\n\\item[o12cnr] -0.296121114543414\n\\item[o13cnr] 0.0391410303938319\n\\item[o14cnr] 0.486759238497325\n\\item[o21cnr] -0.00973202790402701\n\\item[a1] 0.075814973673995\n\\item[o22] -0.0980161725857946\n\\item[o22:a2] 1.18259212498425\n\\item[a1:a2] -0.193433989323675\n\\item[a2] -0.864013129072296\n\\end{description*}\n\n\\item[\\$ci1] A matrix: 6 x 3 of type dbl\n\\begin{tabular}{r|lll}\n  & est & low & upp\\\\\n\\hline\n\tMean Y under bmod, prior med &  3.1651430 &  2.5857085 & 3.62960958\\\\\n\tMean Y under med, prior med &  3.6663180 &  3.3140985 & 4.02752148\\\\\n\tMean diff (bmod-med) for prior med & -0.5011750 & -1.0562817 & 0.06274104\\\\\n\tMean Y under bmod, no prior med &  3.7678942 &  3.4540746 & 4.05290692\\\\\n\tMean Y under med, no prior med &  3.1471095 &  2.8142328 & 3.45923312\\\\\n\tMean diff (bmod-med) for no prior med &  0.6207847 &  0.2064203 & 1.04375882\\\\\n\\end{tabular}\n\n\\item[\\$ci2] NULL\n\\end{description}\n",
            "text/markdown": "$stg1coeff\n:   intercept\n:   3.45750188130161o11c\n:   -0.440704176030666o12c\n:   -0.336616758801142o14c\n:   0.564994887809273o13\n:   -0.0417713658676757o13:a1\n:   -0.560979870289834a1\n:   0.310392366596432\n\n\n$stg2coeff\n:   intercept\n:   3.01829520209932o11cnr\n:   -0.246161848150136o12cnr\n:   -0.296121114543414o13cnr\n:   0.0391410303938319o14cnr\n:   0.486759238497325o21cnr\n:   -0.00973202790402701a1\n:   0.075814973673995o22\n:   -0.0980161725857946o22:a2\n:   1.18259212498425a1:a2\n:   -0.193433989323675a2\n:   -0.864013129072296\n\n\n$ci1\n:   \nA matrix: 6 x 3 of type dbl\n\n| <!--/--> | est | low | upp |\n|---|---|---|---|\n| Mean Y under bmod, prior med |  3.1651430 |  2.5857085 | 3.62960958 |\n| Mean Y under med, prior med |  3.6663180 |  3.3140985 | 4.02752148 |\n| Mean diff (bmod-med) for prior med | -0.5011750 | -1.0562817 | 0.06274104 |\n| Mean Y under bmod, no prior med |  3.7678942 |  3.4540746 | 4.05290692 |\n| Mean Y under med, no prior med |  3.1471095 |  2.8142328 | 3.45923312 |\n| Mean diff (bmod-med) for no prior med |  0.6207847 |  0.2064203 | 1.04375882 |\n\n\n$ci2\n:   NULL\n\n\n",
            "text/html": "<dl>\n\t<dt>$stg1coeff</dt>\n\t\t<dd><dl class=dl-horizontal>\n\t<dt>intercept</dt>\n\t\t<dd>3.45750188130161</dd>\n\t<dt>o11c</dt>\n\t\t<dd>-0.440704176030666</dd>\n\t<dt>o12c</dt>\n\t\t<dd>-0.336616758801142</dd>\n\t<dt>o14c</dt>\n\t\t<dd>0.564994887809273</dd>\n\t<dt>o13</dt>\n\t\t<dd>-0.0417713658676757</dd>\n\t<dt>o13:a1</dt>\n\t\t<dd>-0.560979870289834</dd>\n\t<dt>a1</dt>\n\t\t<dd>0.310392366596432</dd>\n</dl>\n</dd>\n\t<dt>$stg2coeff</dt>\n\t\t<dd><dl class=dl-horizontal>\n\t<dt>intercept</dt>\n\t\t<dd>3.01829520209932</dd>\n\t<dt>o11cnr</dt>\n\t\t<dd>-0.246161848150136</dd>\n\t<dt>o12cnr</dt>\n\t\t<dd>-0.296121114543414</dd>\n\t<dt>o13cnr</dt>\n\t\t<dd>0.0391410303938319</dd>\n\t<dt>o14cnr</dt>\n\t\t<dd>0.486759238497325</dd>\n\t<dt>o21cnr</dt>\n\t\t<dd>-0.00973202790402701</dd>\n\t<dt>a1</dt>\n\t\t<dd>0.075814973673995</dd>\n\t<dt>o22</dt>\n\t\t<dd>-0.0980161725857946</dd>\n\t<dt>o22:a2</dt>\n\t\t<dd>1.18259212498425</dd>\n\t<dt>a1:a2</dt>\n\t\t<dd>-0.193433989323675</dd>\n\t<dt>a2</dt>\n\t\t<dd>-0.864013129072296</dd>\n</dl>\n</dd>\n\t<dt>$ci1</dt>\n\t\t<dd><table>\n<caption>A matrix: 6 x 3 of type dbl</caption>\n<thead>\n\t<tr><th></th><th scope=col>est</th><th scope=col>low</th><th scope=col>upp</th></tr>\n</thead>\n<tbody>\n\t<tr><th scope=row>Mean Y under bmod, prior med</th><td> 3.1651430</td><td> 2.5857085</td><td>3.62960958</td></tr>\n\t<tr><th scope=row>Mean Y under med, prior med</th><td> 3.6663180</td><td> 3.3140985</td><td>4.02752148</td></tr>\n\t<tr><th scope=row>Mean diff (bmod-med) for prior med</th><td>-0.5011750</td><td>-1.0562817</td><td>0.06274104</td></tr>\n\t<tr><th scope=row>Mean Y under bmod, no prior med</th><td> 3.7678942</td><td> 3.4540746</td><td>4.05290692</td></tr>\n\t<tr><th scope=row>Mean Y under med, no prior med</th><td> 3.1471095</td><td> 2.8142328</td><td>3.45923312</td></tr>\n\t<tr><th scope=row>Mean diff (bmod-med) for no prior med</th><td> 0.6207847</td><td> 0.2064203</td><td>1.04375882</td></tr>\n</tbody>\n</table>\n</dd>\n\t<dt>$ci2</dt>\n\t\t<dd>NULL</dd>\n</dl>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "r",
      "display_name": "R",
      "language": "R"
    },
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.3",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}